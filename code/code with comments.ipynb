{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the filter we use to filter some noise in the document\n",
    "import re\n",
    "def change_filter(doc):\n",
    "    txt2 = re.sub(r',|\\.|\\?|<br|/>|\\:|;|\\(|\\)',\"\",doc)\n",
    "    txt3 = re.sub(r'\\'ll',\" will\",txt2)\n",
    "    txt4 = re.sub(r'\\'m',\" am\",txt3)\n",
    "    txt5 = re.sub(r'\\'s',\" is\",txt4)\n",
    "    lowered_tokens = txt5.lower()\n",
    "    return lowered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the vectorizer to vectorize our text samples (unigram model)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=1) \n",
    "X = vectorizer.fit_transform(f)\n",
    "analyze = vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the vectorizer to vectorize our text samples (bigram model)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "analyze = bigram_vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the vectorizer to vectorize our text samples (unigram+bigram model)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bigram_vectorizer = CountVectorizer(ngram_range=(2,2),token_pattern=r'\\b\\w+\\b', min_df=1)\n",
    "analyze = bigram_vectorizer.build_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate vectors for document to train with SVM\n",
    "import numpy as np\n",
    "# posPath = \"/Users/chenjiannan/Documents/UMass/2016Fall/CS585-INLP/project/restaurants/large_movie_review_dataset/test/pos\"\n",
    "# negPath = \"/Users/chenjiannan/Documents/UMass/2016Fall/CS585-INLP/project/restaurants/large_movie_review_dataset/test/neg\"\n",
    "os.chdir(posPath)\n",
    "filenames = os.listdir(posPath)\n",
    "allFiles = []\n",
    "for i in filenames:\n",
    "    if os.path.splitext(i)[1] == '.txt':\n",
    "        allFiles.append(i)\n",
    "print(len(allFiles))\n",
    "flag = True\n",
    "data = np.array([2,3,1,0])\n",
    "for f in allFiles:\n",
    "    if flag == True:\n",
    "        with open(os.path.join(posPath,f),'r',encoding='latin1') as doc:\n",
    "            words = []\n",
    "            content = better_Tokenizer(doc.read())\n",
    "            words.append(content)\n",
    "            data = vectorizer.transform(words).toarray()\n",
    "            flag = False\n",
    "    else:\n",
    "        with open(os.path.join(posPath,f),'r',encoding='latin1') as doc:\n",
    "            words = []\n",
    "            content = better_Tokenizer(doc.read())\n",
    "            words.append(content)\n",
    "            data = np.row_stack((data, vectorizer.transform(words).toarray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#used for SVM training and testing \n",
    "from liblinearutil import *\n",
    "y, x = svm_read_problem('testtrainnew.txt')\n",
    "prob = problem(y, x)\n",
    "param = parameter('-s 3 -c 0.000004')\n",
    "m = train(prob, param)\n",
    "CV_ACC = train(y, x, '-v 3')\n",
    "best_C, best_rate = train(y, x, '-C -s 0')\n",
    "y1, x1 = svm_read_problem('testtestnew.txt')\n",
    "p_labs, p_acc, p_vals = predict(y1, x1, m, '-q')\n",
    "print(p_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read from inspection records and restaurant records\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "f = open(os.path.join(os.getcwd(),\"restaurant_inspections.csv\"),\"r\").readlines()\n",
    "file1 = open('r_inspections3.csv','w')\n",
    "for line in f:\n",
    "    b = line.split(';')\n",
    "    file1.write(b[0]+\",\"+b[1]+\",\"+b[2]+\",\"+b[3]+\",\"+b[4]+\",\"+b[5]+\",\"+b[6]+\",\"+b[7]+\",\"+b[8]+\",\"+b[9]+\",\"+b[10]+\",\"+b[11]+\",\"+b[12]+\",\"+b[13]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#address matching \n",
    "import re\n",
    "import os\n",
    "from streetaddress import StreetAddressFormatter, StreetAddressParser\n",
    "from collections import defaultdict\n",
    "\n",
    "addr_parser = StreetAddressParser()\n",
    "f1 = open(os.path.join(os.getcwd(),\"restaurant_establishments.csv\"),\"r\").readlines()\n",
    "file2 = open('r_est2.txt','w')\n",
    "tSet = set()\n",
    "tDict = defaultdict(str)\n",
    "print(\"len1\",len(f1))\n",
    "pattern3 = re.compile(r'^[snew]\\s')\n",
    "for line in f1[1:]:\n",
    "    num = re.sub(r';', \" \", line)\n",
    "    b = line.split(\";\")\n",
    "    facility_id = b[1]\n",
    "    b2 = re.sub(r\"\\n\",\"\",b[5])\n",
    "    b2 = re.sub(r\"\\'|\\*|\\.|\\,|\\n\",\"\",b2)\n",
    "    b2 = b2.lower()\n",
    "    addr = defaultdict(str)\n",
    "    addr = addr_parser.parse(b2)\n",
    "    street_name = str(addr['street_name'])\n",
    "    result = re.match(pattern3, street_name)\n",
    "    house = str(addr['house'])\n",
    "    street_type = str(addr['street_type'])\n",
    "    if result:\n",
    "        street_name = addr['street_name'][2:]\n",
    "    if house =='None':\n",
    "        house = ''\n",
    "    else:\n",
    "        house = house+\" \"\n",
    "    if street_type=='None':\n",
    "        street_type = ''\n",
    "    else:\n",
    "        street_type = \" \"+street_type\n",
    "    address = house+street_name+street_type\n",
    "    if address not in tDict.keys():\n",
    "        tDict[address] = facility_id\n",
    "        file2.write(address+\";\"+facility_id+\"\\n\")\n",
    "    tSet.add(address)\n",
    "print(\"len1\",len(tSet))\n",
    "print(tDict)\n",
    "print(\"len4\",len(tDict))\n",
    "\n",
    "import json\n",
    "f3 = open(os.path.join(os.getcwd(),\"vegas_business.txt\"),\"r\").readlines()\n",
    "file3 = open('r_business.txt','w')\n",
    "pattern1 = re.compile(r'\\d+.+')\n",
    "pattern2 = re.compile(r'.+\\n(\\d+.+)\\s+\\S+')\n",
    "count = 1\n",
    "f4=open('result.txt','w')\n",
    "print(len(f3))\n",
    "for line in f3:\n",
    "    decode = json.loads(line)\n",
    "    st = decode['full_address']\n",
    "    name = decode['name']\n",
    "    business_id = decode['business_id']\n",
    "    result = re.match(pattern1, st)\n",
    "    if result:\n",
    "        print(result.group(),\"---\",count)\n",
    "        f4.write(name+\";\"+result.group()+\";\"+business_id+'\\n')\n",
    "        count=count+1\n",
    "    else:\n",
    "        result2 = re.match(pattern2, st)\n",
    "        if result2:\n",
    "            print(result2.group(1),\"---\",count)\n",
    "            f4.write(name+\";\"+result2.group(1)+\";\"+business_id+'\\n')\n",
    "            count=count+1\n",
    "        else:\n",
    "            print(st)\n",
    "f4.close()\n",
    "\n",
    "from streetaddress import StreetAddressFormatter, StreetAddressParser\n",
    "f5 = open(os.path.join(os.getcwd(),\"result.txt\"),\"r\").readlines()\n",
    "file4 = open('r_business1.txt','w')\n",
    "print(\"len3\",len(f5))\n",
    "pattern4 = re.compile(r'^[snew]\\s')\n",
    "count = 0\n",
    "oSet = set()\n",
    "newSet = set()\n",
    "for line in f5:\n",
    "    s = re.sub(r\"\\n\",\"\",line)\n",
    "    segments = s.split(';')\n",
    "    s1 = segments[0]\n",
    "    s2 = segments[1]\n",
    "    s1 = s1.lower()\n",
    "    s2 = s2.lower()\n",
    "    s1 = re.sub(r\"\\'|\\*|\\.|\\,|\\n\",\"\",s1)\n",
    "    s2 = re.sub(r\"\\'|\\*|\\.|\\,|\\n\",\"\",s2)\n",
    "    if s2 in oSet:\n",
    "        print(s2)\n",
    "    oSet.add(s2)\n",
    "    addr = addr_parser.parse(s2)\n",
    "    street_name = str(addr['street_name'])\n",
    "    result = re.match(pattern3, street_name)\n",
    "    house = str(addr['house'])\n",
    "    street_type = str(addr['street_type'])\n",
    "    if result:\n",
    "        street_name = addr['street_name'][2:]\n",
    "    if house =='None':\n",
    "        house = ''\n",
    "    else:\n",
    "        house = house+\" \"\n",
    "    if street_type=='None':\n",
    "        street_type = ''\n",
    "    else:\n",
    "        street_type = \" \"+street_type\n",
    "    address = house+street_name+street_type\n",
    "    newSet.add(address)\n",
    "    if address in tSet:\n",
    "        print(s1,\",\",address,\",\",segments[2])\n",
    "        tSet.remove(address)\n",
    "        file4.write(s1+\";\"+address+\";\"+segments[2]+\"\\n\")\n",
    "        count=count+1\n",
    "print(\"len4\",count)\n",
    "print(\"len5\",len(newSet))\n",
    "print(\"len5\",len(oSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#facility id to business id\n",
    "import os\n",
    "import json\n",
    "f6 =open('r_est2.txt','r').readlines()\n",
    "f5 = open('r_business1.txt','r').readlines()\n",
    "# file10 = open('fidTobid','w')\n",
    "fname6 = []\n",
    "fname5 = []\n",
    "fidTobid = {}\n",
    "bidTofid = {}\n",
    "for line in f6:\n",
    "    b = line.split(\";\")\n",
    "    for line1 in f5:\n",
    "        b1 = line1.split(\";\")\n",
    "        if b[0]==b1[1]:\n",
    "            fidTobid[b[1][:-1]] = b1[2][:-1]\n",
    "            bidTofid[b1[2][:-1]] = b[1][:-1]\n",
    "# file10.write(str(fidTobid))\n",
    "print(fidTobid)\n",
    "print(bidTofid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate inspection list for each facility\n",
    "f5 = open('r_business1.txt','r').readlines()\n",
    "f6 =open('r_est2.txt','r').readlines()\n",
    "time_span = defaultdict(list)\n",
    "fname5 = set()\n",
    "fname6 = defaultdict(str)\n",
    "for line in f6:\n",
    "    b = line.split(\";\")\n",
    "    fname6[b[0]] = b[1][:-1]\n",
    "# print(fname6)\n",
    "for line in f5:\n",
    "    b = line.split(\";\")\n",
    "    inspection_id = fname6[b[1]]\n",
    "    fname5.add(b[1])\n",
    "#     print(inspection_id)\n",
    "    spanList = sorted(getTimeSpan(inspection_id))\n",
    "#     print(spanList)\n",
    "    if len(spanList)<3 and len(spanList)>0:\n",
    "        time_span[inspection_id] = spanList\n",
    "print(time_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create samples for both classes from reviews\n",
    "import json \n",
    "\n",
    "def getReviewsNew(ilist, fileLines):\n",
    "    posDir = 'posNew/'\n",
    "    negDir = 'negNew/'\n",
    "    removeList = []\n",
    "#     f3 = open(os.path.join(os.getcwd(),\"vegas_reviews_new.json\"),\"r\").readlines()\n",
    "    timeStart = ilist[0][3]\n",
    "    fid = ilist[0][2]\n",
    "    reviews = ''\n",
    "    for line in fileLines:\n",
    "        decode = json.loads(line)\n",
    "        time = datetime.datetime.strptime(decode['date'],\"%Y-%m-%d\")\n",
    "        bid = fidTobid[fid]\n",
    "        if bid == decode['business_id'] and time<timeStart:\n",
    "            reviews = reviews+decode['text']\n",
    "            removeList.append(line)\n",
    "    if ilist[0][7]>10 and len(reviews)>0:\n",
    "        fileTemp = open(posDir+fid+str(timeStart)+\".txt\",'w')\n",
    "        fileTemp.write(reviews)\n",
    "        fileTemp.close()\n",
    "    elif ilist[0][7]<=10 and len(reviews)>0:\n",
    "        fileTemp = open(negDir+fid+str(timeStart)+\".txt\",'w')\n",
    "        fileTemp.write(reviews)\n",
    "        fileTemp.close()\n",
    "    for k in range(0,len(ilist)-1):\n",
    "        seg1 = ilist[k]\n",
    "        seg2 = ilist[k+1]\n",
    "        timeStart = seg1[3]\n",
    "        timeEnd = seg2[3]\n",
    "        reviews = ''\n",
    "        for line in fileLines:\n",
    "            decode = json.loads(line)\n",
    "            time = datetime.datetime.strptime(decode['date'],\"%Y-%m-%d\")\n",
    "            bid = fidTobid[fid]\n",
    "            if bid == decode['business_id'] and time>timeStart and time<timeEnd:\n",
    "                reviews = reviews+decode['text']\n",
    "                removeList.append(line)\n",
    "        if seg2[7]>10 and len(reviews)>0:\n",
    "            fileTemp = open(posDir+fid+str(timeEnd)+\".txt\",'w')\n",
    "            fileTemp.write(reviews)\n",
    "            fileTemp.close()\n",
    "        elif seg2[7]<=10 and len(reviews)>0:\n",
    "            fileTemp = open(negDir+fid+str(timeEnd)+\".txt\",'w')\n",
    "            fileTemp.write(reviews)\n",
    "            fileTemp.close()\n",
    "    return removeList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get statistical features like average rating, non-positive review count and review count\n",
    "import json \n",
    "from __future__ import division\n",
    "def getFeatures(ilist, fileLines):\n",
    "    posDir = 'posNew/'\n",
    "    negDir = 'negNew/'\n",
    "    removeList = []\n",
    "#     f3 = open(os.path.join(os.getcwd(),\"vegas_reviews_new.json\"),\"r\").readlines()\n",
    "    timeStart = ilist[0][3]\n",
    "    fid = ilist[0][2]\n",
    "    reviews = ''\n",
    "    totalRating = 0\n",
    "    negReviews = 0\n",
    "    reviewWords = 0\n",
    "    reviewCount = 0 \n",
    "    for line in fileLines:\n",
    "        decode = json.loads(line)\n",
    "        time = datetime.datetime.strptime(decode['date'],\"%Y-%m-%d\")\n",
    "        bid = fidTobid[fid]\n",
    "        if bid == decode['business_id'] and time<timeStart:\n",
    "            reviews = reviews+decode['text']\n",
    "            reviewWords = reviewWords+len(reviews.split())\n",
    "            rating = float(decode['stars'])\n",
    "            totalRating = totalRating+rating\n",
    "            reviewCount=reviewCount+1\n",
    "            if rating<=3:\n",
    "                negReviews = negReviews+1\n",
    "            removeList.append(line)\n",
    "    if ilist[0][7]>10 and len(reviews)>0:\n",
    "        fileTemp = open(posDir+fid+str(timeStart)+\".txt\",'w')\n",
    "        fileTemp.write(\"rc:\"+str(reviewWords)+\" ar:\"+str(totalRating/reviewCount)+\" nr:\"+str(negReviews))\n",
    "        fileTemp.close()\n",
    "    elif ilist[0][7]<=10 and len(reviews)>0:\n",
    "        fileTemp = open(negDir+fid+str(timeStart)+\".txt\",'w')\n",
    "        fileTemp.write(\"rc:\"+str(reviewWords)+\" ar:\"+str(totalRating/reviewCount)+\" nr:\"+str(negReviews))\n",
    "        fileTemp.close()\n",
    "    for k in range(0,len(ilist)-1):\n",
    "        seg1 = ilist[k]\n",
    "        seg2 = ilist[k+1]\n",
    "        timeStart = seg1[3]\n",
    "        timeEnd = seg2[3]\n",
    "        reviews = ''\n",
    "        totalRating = 0\n",
    "        negReviews = 0\n",
    "        reviewWords = 0\n",
    "        reviewCount = 0 \n",
    "        for line in fileLines:\n",
    "            decode = json.loads(line)\n",
    "            time = datetime.datetime.strptime(decode['date'],\"%Y-%m-%d\")\n",
    "            bid = fidTobid[fid]\n",
    "            if bid == decode['business_id'] and time>timeStart and time<timeEnd:\n",
    "                reviews = reviews+decode['text']\n",
    "                reviewWords = reviewWords+len(reviews.split())\n",
    "                rating = float(decode['stars'])\n",
    "                totalRating = totalRating+rating\n",
    "                reviewCount=reviewCount+1\n",
    "                if rating<=3:\n",
    "                    negReviews = negReviews+1\n",
    "                removeList.append(line)\n",
    "        if seg2[7]>10 and len(reviews)>0:\n",
    "            fileTemp = open(posDir+fid+str(timeEnd)+\".txt\",'w')\n",
    "            fileTemp.write(\"rc:\"+str(reviewWords)+\" ar:\"+str(totalRating/reviewCount)+\" nr:\"+str(negReviews))\n",
    "            fileTemp.close()\n",
    "        elif seg2[7]<=10 and len(reviews)>0:\n",
    "            fileTemp = open(negDir+fid+str(timeEnd)+\".txt\",'w')\n",
    "            fileTemp.write(\"rc:\"+str(reviewWords)+\" ar:\"+str(totalRating/reviewCount)+\" nr:\"+str(negReviews))\n",
    "            fileTemp.close()\n",
    "    return removeList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
